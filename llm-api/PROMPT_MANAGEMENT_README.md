# æç¤ºè¯ç®¡ç†åŠŸèƒ½è¯´æ˜

æœ¬é¡¹ç›®å·²é›†æˆç»Ÿä¸€çš„æç¤ºè¯è‡ªå®šä¹‰åŠŸèƒ½ï¼Œæ”¯æŒæ™ºèƒ½ä½“ç®¡ç†ã€æ¨¡æ¿ç³»ç»Ÿå’Œè‡ªå®šä¹‰æç¤ºè¯ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

### 1. æ™ºèƒ½ä½“ç®¡ç†
- **é¢„å®šä¹‰è§’è‰²**: åŠ©æ‰‹ã€åˆ†æå¸ˆã€ç¿»è¯‘å‘˜ã€ç¨‹åºå‘˜ã€æ•™å¸ˆã€ä½œå®¶ã€ç ”ç©¶å‘˜ã€é¡¾é—®
- **è‡ªå®šä¹‰é…ç½®**: æ”¯æŒè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ã€æ¸©åº¦ã€æœ€å¤§ä»¤ç‰Œæ•°ç­‰å‚æ•°
- **æŒä¹…åŒ–å­˜å‚¨**: æ™ºèƒ½ä½“é…ç½®è‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
- **åŠ¨æ€åˆ‡æ¢**: å¯åœ¨å¯¹è¯è¿‡ç¨‹ä¸­éšæ—¶åˆ‡æ¢æ™ºèƒ½ä½“

### 2. æ¨¡æ¿ç³»ç»Ÿ
- **å†…ç½®æ¨¡æ¿**: æä¾›å¤šç§é¢„å®šä¹‰çš„æç¤ºè¯æ¨¡æ¿
- **æ¨¡æ¿å‚æ•°**: æ”¯æŒæ¨¡æ¿å‚æ•°åŒ–ï¼Œå¯åŠ¨æ€æ›¿æ¢å†…å®¹
- **å¿«é€Ÿåˆ›å»º**: åŸºäºæ¨¡æ¿å¿«é€Ÿåˆ›å»ºæ–°çš„æ™ºèƒ½ä½“
- **æ¨¡æ¿æœç´¢**: æ”¯æŒæŒ‰æ ‡ç­¾å’Œå…³é”®è¯æœç´¢æ¨¡æ¿

### 3. APIæ¥å£
- **RESTful API**: å®Œæ•´çš„REST APIæ”¯æŒ
- **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤æ“ä½œ
- **æ ¼å¼åŒ–åŠŸèƒ½**: æ”¯æŒæ¨¡æ¿æ ¼å¼åŒ–å’Œå‚æ•°æ›¿æ¢

## ğŸ“ æ–‡ä»¶ç»“æ„

```
llm-api/
â”œâ”€â”€ prompt_manager.py      # æ ¸å¿ƒæç¤ºè¯ç®¡ç†æ¨¡å—
â”œâ”€â”€ prompt_api.py          # REST APIæ¥å£
â”œâ”€â”€ client.py              # é›†æˆæ™ºèƒ½ä½“åŠŸèƒ½çš„LLMå®¢æˆ·ç«¯
â”œâ”€â”€ app.py                 # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ chat-webui.py          # Streamlit Webç•Œé¢
â”œâ”€â”€ demo_prompt_management.py  # åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
â””â”€â”€ prompts/               # æç¤ºè¯å­˜å‚¨ç›®å½•
    â”œâ”€â”€ templates/         # æ¨¡æ¿æ–‡ä»¶
    â””â”€â”€ agents/           # æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶
```

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œä½¿ç”¨

```python
from client import LLMClient
from prompt_manager import get_prompt_manager

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = LLMClient()
prompt_manager = get_prompt_manager()

# æŸ¥çœ‹å¯ç”¨æ¨¡æ¿
templates = prompt_manager.list_templates()
print(f"å¯ç”¨æ¨¡æ¿: {templates}")

# ä»æ¨¡æ¿åˆ›å»ºæ™ºèƒ½ä½“
client.create_agent_from_template(
    agent_id="my_assistant",
    template_id="assistant",
    name="æˆ‘çš„åŠ©æ‰‹",
    custom_params={"temperature": 0.7}
)

# è®¾ç½®å½“å‰æ™ºèƒ½ä½“
client.set_agent("my_assistant")

# ä¸æ™ºèƒ½ä½“å¯¹è¯
response = client.chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
print(response)
```

### 2. Webç•Œé¢ä½¿ç”¨

å¯åŠ¨Streamlitç•Œé¢ï¼š
```bash
streamlit run chat-webui.py
```

åœ¨ä¾§è¾¹æ ä¸­ï¼š
1. é€‰æ‹©æˆ–åˆ›å»ºæ™ºèƒ½ä½“
2. æŸ¥çœ‹æ™ºèƒ½ä½“é…ç½®
3. ä¸æ™ºèƒ½ä½“å¯¹è¯

### 3. APIæ¥å£ä½¿ç”¨

å¯åŠ¨FastAPIæœåŠ¡å™¨ï¼š
```bash
python app.py
```

è®¿é—®APIæ–‡æ¡£ï¼šhttp://localhost:8000/docs

#### ä¸»è¦APIç«¯ç‚¹ï¼š

- `GET /api/prompts/templates` - è·å–æ‰€æœ‰æ¨¡æ¿
- `POST /api/prompts/templates` - åˆ›å»ºæ–°æ¨¡æ¿
- `GET /api/prompts/agents` - è·å–æ‰€æœ‰æ™ºèƒ½ä½“
- `POST /api/prompts/agents` - åˆ›å»ºæ–°æ™ºèƒ½ä½“
- `POST /api/prompts/chat/{agent_id}` - ä¸æŒ‡å®šæ™ºèƒ½ä½“å¯¹è¯

### 4. æ¼”ç¤ºè„šæœ¬

è¿è¡Œæ¼”ç¤ºè„šæœ¬æŸ¥çœ‹å®Œæ•´åŠŸèƒ½ï¼š
```bash
python demo_prompt_management.py
```

## ğŸ¤– é¢„å®šä¹‰æ™ºèƒ½ä½“è§’è‰²

| è§’è‰² | æè¿° | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| assistant | é€šç”¨åŠ©æ‰‹ | æ—¥å¸¸é—®ç­”ã€ä»»åŠ¡ååŠ© |
| analyst | æ•°æ®åˆ†æå¸ˆ | æ•°æ®åˆ†æã€æŠ¥å‘Šç”Ÿæˆ |
| translator | ç¿»è¯‘å‘˜ | å¤šè¯­è¨€ç¿»è¯‘ |
| coder | ç¨‹åºå‘˜ | ä»£ç ç¼–å†™ã€è°ƒè¯• |
| teacher | æ•™å¸ˆ | æ•™å­¦ã€çŸ¥è¯†è§£é‡Š |
| writer | ä½œå®¶ | å†…å®¹åˆ›ä½œã€æ–‡æ¡ˆå†™ä½œ |
| researcher | ç ”ç©¶å‘˜ | å­¦æœ¯ç ”ç©¶ã€æ–‡çŒ®åˆ†æ |
| consultant | é¡¾é—® | ä¸“ä¸šå’¨è¯¢ã€å»ºè®®æä¾› |

## ğŸ“ è‡ªå®šä¹‰æ¨¡æ¿

### åˆ›å»ºæ–°æ¨¡æ¿

```python
from prompt_manager import PromptTemplate, AgentRole

# åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
template = PromptTemplate(
    id="custom_helper",
    name="è‡ªå®šä¹‰åŠ©æ‰‹",
    role=AgentRole.ASSISTANT,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{domain}åŠ©æ‰‹ï¼Œæ“…é•¿{skills}ã€‚",
    description="å¯è‡ªå®šä¹‰é¢†åŸŸå’ŒæŠ€èƒ½çš„åŠ©æ‰‹æ¨¡æ¿",
    parameters=["domain", "skills"],
    examples=[
        {
            "domain": "åŒ»ç–—",
            "skills": "è¯Šæ–­å»ºè®®å’Œå¥åº·å’¨è¯¢",
            "result": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œæ“…é•¿è¯Šæ–­å»ºè®®å’Œå¥åº·å’¨è¯¢ã€‚"
        }
    ],
    tags=["è‡ªå®šä¹‰", "é€šç”¨"],
    language="zh"
)

# ä¿å­˜æ¨¡æ¿
prompt_manager.save_template(template)
```

### ä½¿ç”¨å‚æ•°åŒ–æ¨¡æ¿

```python
# æ ¼å¼åŒ–æ¨¡æ¿
formatted_prompt = prompt_manager.format_template(
    "custom_helper",
    domain="ç¼–ç¨‹",
    skills="Pythonå¼€å‘å’Œä»£ç ä¼˜åŒ–"
)
print(formatted_prompt)
# è¾“å‡º: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ“…é•¿Pythonå¼€å‘å’Œä»£ç ä¼˜åŒ–ã€‚"
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

åœ¨`.env`æ–‡ä»¶ä¸­é…ç½®APIå¯†é’¥ï¼š
```env
# OpenAI
OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic
ANTHROPIC_API_KEY=your_anthropic_api_key

# Groq
GROQ_API_KEY=your_groq_api_key

# DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key

# å…¶ä»–é…ç½®
DEFAULT_PROVIDER=openai
DEFAULT_CHAT_MODEL=gpt-4o-mini
REQUEST_TIMEOUT=30
MAX_RETRIES=3
```

### æ™ºèƒ½ä½“é…ç½®å‚æ•°

```python
from prompt_manager import AgentConfig, AgentRole

agent_config = AgentConfig(
    id="my_agent",
    name="æˆ‘çš„æ™ºèƒ½ä½“",
    role=AgentRole.ASSISTANT,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹...",
    temperature=0.7,        # åˆ›é€ æ€§ (0.0-2.0)
    max_tokens=2000,        # æœ€å¤§è¾“å‡ºé•¿åº¦
    model="gpt-4o-mini",    # æŒ‡å®šæ¨¡å‹
    provider="openai",      # æŒ‡å®šæä¾›å•†
    custom_params={         # è‡ªå®šä¹‰å‚æ•°
        "top_p": 0.9,
        "frequency_penalty": 0.0
    }
)
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. æ¨¡æ¿æœç´¢

```python
# æŒ‰æ ‡ç­¾æœç´¢
templates = prompt_manager.search_templates(tags=["ç¼–ç¨‹"])

# æŒ‰å…³é”®è¯æœç´¢
templates = prompt_manager.search_templates(query="ç¿»è¯‘")

# æŒ‰è§’è‰²æœç´¢
templates = prompt_manager.get_templates_by_role(AgentRole.CODER)
```

### 2. æ‰¹é‡æ“ä½œ

```python
# æ‰¹é‡åˆ›å»ºæ™ºèƒ½ä½“
agents_data = [
    {"id": "agent1", "template_id": "assistant", "name": "åŠ©æ‰‹1"},
    {"id": "agent2", "template_id": "coder", "name": "ç¨‹åºå‘˜1"}
]

for agent_data in agents_data:
    client.create_agent_from_template(**agent_data)
```

### 3. åŠ¨æ€å‚æ•°

```python
# åœ¨å¯¹è¯ä¸­åŠ¨æ€è®¾ç½®å‚æ•°
response = client.chat(
    "è¯·å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°",
    temperature=0.3,  # ä¸´æ—¶é™ä½åˆ›é€ æ€§
    max_tokens=1000   # é™åˆ¶è¾“å‡ºé•¿åº¦
)
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **APIå¯†é’¥å®‰å…¨**: è¯·å¦¥å–„ä¿ç®¡APIå¯†é’¥ï¼Œä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
2. **æ–‡ä»¶æƒé™**: ç¡®ä¿`prompts/`ç›®å½•æœ‰è¯»å†™æƒé™
3. **æ¨¡å‹å…¼å®¹æ€§**: ä¸åŒæ¨¡å‹å¯¹å‚æ•°çš„æ”¯æŒå¯èƒ½æœ‰å·®å¼‚
4. **èµ„æºä½¿ç”¨**: é•¿å¯¹è¯å¯èƒ½æ¶ˆè€—è¾ƒå¤šAPIé…é¢
5. **å¹¶å‘é™åˆ¶**: æ³¨æ„APIæä¾›å•†çš„å¹¶å‘è¯·æ±‚é™åˆ¶

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥**
   - æ£€æŸ¥æ¨¡æ¿IDæ˜¯å¦å­˜åœ¨
   - ç¡®è®¤æ™ºèƒ½ä½“IDæœªé‡å¤
   - éªŒè¯å‚æ•°æ ¼å¼æ˜¯å¦æ­£ç¡®

2. **APIè°ƒç”¨å¤±è´¥**
   - æ£€æŸ¥APIå¯†é’¥é…ç½®
   - ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—ä¿¡æ¯

3. **æ¨¡æ¿åŠ è½½é”™è¯¯**
   - æ£€æŸ¥`prompts/templates/`ç›®å½•æƒé™
   - éªŒè¯JSONæ–‡ä»¶æ ¼å¼
   - ç¡®è®¤æ–‡ä»¶ç¼–ç ä¸ºUTF-8

### æ—¥å¿—è°ƒè¯•

```python
import logging

# å¯ç”¨è°ƒè¯•æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
try:
    client.chat("æµ‹è¯•æ¶ˆæ¯")
except Exception as e:
    logging.error(f"å¯¹è¯å¤±è´¥: {e}")
```

## ğŸ“š æ›´å¤šèµ„æº

- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Streamlitæ–‡æ¡£](https://docs.streamlit.io/)
- [LangChainæ–‡æ¡£](https://python.langchain.com/)
- [é¡¹ç›®GitHubä»“åº“](https://github.com/your-repo/llm-api)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. å‘èµ·Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚